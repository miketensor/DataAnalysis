{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import sys\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filename):\n",
    "    dataset = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        try: \n",
    "            for row in reader:\n",
    "                dataset.append(row)\n",
    "        except csv.Error as e:\n",
    "            sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))\n",
    "    return dataset\n",
    "     \n",
    "dataset = load_file('sonar.all-data.csv')          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_float(data, nb_lines, size_row):\n",
    "    for row in range(nb_lines):\n",
    "        for i in range(size_row-1):\n",
    "            data[row][i] = float(data[row][i])\n",
    "    return data\n",
    "\n",
    "dataset = convert_float(dataset, len(dataset), len(dataset[0]))\n",
    "#print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_class_values(data):\n",
    "    dict = {}\n",
    "    index = -1\n",
    "    values = []\n",
    "    i = 0\n",
    "    for row in data:\n",
    "        if not(row[-1] in values):\n",
    "            index +=1\n",
    "            values.append(row[-1])\n",
    "        data[i][-1] = index\n",
    "        i += 1\n",
    "    return data\n",
    "\n",
    "dataset = convert_class_values(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(groups, class_values):\n",
    "    gini = 0.0\n",
    "    nb_total = sum([len(group) for group in groups])\n",
    "    \n",
    "    #print(nb_total)\n",
    "    for group in groups: # left and right group\n",
    "        size = len(group)\n",
    "        if size == 0: continue\n",
    "        \n",
    "        score = 0\n",
    "        for class_value in class_values:\n",
    "            p = [row[-1] for row in group].count(class_value) / float(size)\n",
    "            score += p * p\n",
    "        gini += (1 - score) * (size / nb_total)  #weight score by size of the group\n",
    "            \n",
    "            #print('class value ', class_value)\n",
    "            #print('Group ', proportion)\n",
    "            #print('gini ', gini)\n",
    "    return gini\n",
    "\n",
    "def get_gini(sub_dataset, row_nb, index_col):\n",
    "    left, right = [],[]\n",
    "    left_class, right_class = [],[]\n",
    "    value_pivot = sub_dataset[row_nb][index_col]\n",
    "    \n",
    "    for row in sub_dataset:\n",
    "        if row[index_col] < value_pivot:\n",
    "            left.append(row)\n",
    "            left_class.append(row[-1])\n",
    "        else:\n",
    "            right.append(row)\n",
    "            right_class.append(row[-1])\n",
    "    \n",
    "    groups = []\n",
    "    groups.append(left)\n",
    "    groups.append(right)\n",
    "    class_values= [0, 1]\n",
    "    gini = gini_index(groups, class_values)\n",
    "    return gini, {'left': left, 'right': right}\n",
    "\n",
    "#gini, left, right = get_gini(dataset,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return tree node \n",
    "# Groups of the node contain two sub groups : left and right\n",
    "def split(sub_dataset):\n",
    "    # select random index to split\n",
    "    gini_ref = 999\n",
    "    gini_tmp = 999\n",
    "    row_ref = 0\n",
    "    group_ref = {}\n",
    "    group_tmp = {}\n",
    "    random.seed()\n",
    "    index_col = random.randrange(len(dataset[0])-1)                         \n",
    "    \n",
    "    # split in an arbitrary way based on the value of the half of the sub dataset\n",
    "    #row_ref = int(len(sub_dataset)/2)\n",
    "    #value_ref = sub_dataset[row_ref][index_col]\n",
    "    #left, right=[],[]\n",
    "    #for row in sub_dataset:\n",
    "    #    if row[index_col] < value_ref: left.append(row)\n",
    "    #    else: right.append(row)\n",
    "    #group_ref = {'left': left, 'right' : right}    \n",
    "    \n",
    "    # determine the best row/value to split\n",
    "    for row_nb in range(len(sub_dataset)):\n",
    "        gini_tmp, group_tmp = get_gini(sub_dataset, row_nb, index_col)\n",
    "        #print(gini_tmp)\n",
    "        if gini_tmp < gini_ref:\n",
    "            gini_ref = gini_tmp\n",
    "            group_ref = group_tmp\n",
    "            value_ref = sub_dataset[row_nb][index_col]\n",
    "            row_ref = row_nb\n",
    "            \n",
    "    return {'feature': index_col, 'row': row_ref, 'value': value_ref, 'groups': group_ref}\n",
    "\n",
    "#split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminal_node(sub_dataset):\n",
    "    outcomes = [row[-1] for row in sub_dataset]\n",
    "    return max(set(outcomes), key=outcomes.count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(node, dataset, nb_features, num_feature):\n",
    "    # if parent_tree not existing => root\n",
    "    #if not('feature' in parent_tree.keys()):    \n",
    "    #    parent_tree = split(dataset)\n",
    "    #    build_tree(parent_tree, dataset, nb_features, num_feature+1)    \n",
    "    #split the left group in sub child tree\n",
    "    #else:\n",
    "        if (num_feature<nb_features):\n",
    "            #print('Left Length: ' ,len(node['groups']['left']))\n",
    "            #print('Right Length: ' ,len(parent_tree['groups']['right']))\n",
    "            if len(node['groups']['left']) > 0:\n",
    "                node['left'] = split(node['groups']['left'])\n",
    "                build_tree(node['left'], node['groups']['left'], nb_features, num_feature+1) \n",
    "            if len(node['groups']['right']) > 0:\n",
    "                node['right'] = split(node['groups']['right'])\n",
    "                build_tree(node['right'], node['groups']['right'], nb_features, num_feature+1) \n",
    "        # terminal node\n",
    "        else:\n",
    "            #print('terminal')\n",
    "            if len(node['groups']['left']) > 0:\n",
    "                node['left'] = terminal_node(node['groups']['left'])\n",
    "                #print(terminal_node(node['groups']['left']))                \n",
    "            if len(node['groups']['right']) > 0:\n",
    "                node['right'] = terminal_node(node['groups']['right'])\n",
    "                #print('right ' , terminal_node(node['groups']['right']))\n",
    "    \n",
    "root=split(dataset)\n",
    "#print(root.indexes)\n",
    "build_tree(root,dataset,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomforest\n",
    "def randomforest(dataset, nb_trees = 5, nb_features = 5):\n",
    "    trees =[]\n",
    "    for i in range(nb_trees):\n",
    "        root = split(dataset)\n",
    "        build_tree(root, dataset, nb_features, 1)\n",
    "        trees.append(root)\n",
    "    return trees\n",
    "\n",
    "trees = randomforest( dataset, nb_trees = 5, nb_features=5)\n",
    "#print(trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def predict(node, row):\n",
    "    #print('feature ', node['feature'])\n",
    "    #print(row[node['feature']], ' vs ', node['value'] )\n",
    "    if row[node['feature']] < node['value']:\n",
    "        if isinstance(node['left'], dict): \n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict): \n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "        \n",
    "value = predict(root, dataset[0])\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bagging_prediction(trees, row):\n",
    "    predictions = [predict(tree, row) for tree in trees]\n",
    "    print(predictions)\n",
    "    return max(set(predictions), key=predictions.count)\n",
    "\n",
    "bagging_prediction(trees, dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02, 0.0371, 0.0428, 0.0207, 0.0954, 0.0986, 0.1539, 0.1601, 0.3109, 0.2111, 0.1609, 0.1582, 0.2238, 0.0645, 0.066, 0.2273, 0.31, 0.2999, 0.5078, 0.4797, 0.5783, 0.5071, 0.4328, 0.555, 0.6711, 0.6415, 0.7104, 0.808, 0.6791, 0.3857, 0.1307, 0.2604, 0.5121, 0.7547, 0.8537, 0.8507, 0.6692, 0.6097, 0.4943, 0.2744, 0.051, 0.2834, 0.2825, 0.4256, 0.2641, 0.1386, 0.1051, 0.1343, 0.0383, 0.0324, 0.0232, 0.0027, 0.0065, 0.0159, 0.0072, 0.0167, 0.018, 0.0084, 0.009, 0.0032, 0]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
